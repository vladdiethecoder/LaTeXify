#!/usr/bin/env python3
"""One-command launcher for the LaTeXify pipeline."""
from __future__ import annotations

import argparse
import json
from pathlib import Path

from latexify.pipeline.langchain_orchestrator import PipelineConfig, run_pipeline

DEV_INPUTS = Path(__file__).resolve().parent / "dev" / "inputs"


def _resolve_pdf(path_like: str | None) -> Path:
    if not path_like:
        raise ValueError("--pdf is required unless --list-inputs is used")
    candidate = Path(path_like).expanduser().resolve()
    if candidate.exists():
        return candidate
    fallback = DEV_INPUTS / path_like
    if fallback.exists():
        return fallback.resolve()
    raise FileNotFoundError(f"Could not find PDF at {candidate} or {fallback}")


def _list_inputs() -> None:
    DEV_INPUTS.mkdir(parents=True, exist_ok=True)
    files = sorted(p for p in DEV_INPUTS.glob("*.pdf"))
    if not files:
        print("(dev/inputs is empty)")
        return
    print("Available PDFs in dev/inputs:\n")
    for path in files:
        print(f"- {path.name}")


def main() -> int:
    parser = argparse.ArgumentParser(description="Run the LaTeXify pipeline locally")
    parser.add_argument("--pdf", type=str, help="PDF filename (relative to dev/inputs) or an absolute path")
    parser.add_argument("--title", type=str, default=None, help="Document title override")
    parser.add_argument("--author", type=str, default="Generated by LaTeXify", help="Author metadata")
    parser.add_argument("--course", type=str, default="", help="Optional course/class metadata")
    parser.add_argument("--run-root", type=Path, default=Path("dev/runs"), help="Where to store ingestion runs")
    parser.add_argument("--build-dir", type=Path, default=Path("build"), help="Where to emit assembled outputs")
    parser.add_argument("--langchain", action="store_true", help="Execute via LangChain RunnableSequence")
    parser.add_argument("--prefer-remote-layout", action="store_true", help="Use remote layout planner endpoint if available")
    parser.add_argument("--skip-qa", action="store_true", help="Disable QA/auto-fix stage")
    parser.add_argument("--qa-compile", action="store_true", help="Attempt latexmk inside QA preflight")
    parser.add_argument("--no-aggregate", action="store_true", help="Skip snippet aggregation into main.tex")
    parser.add_argument("--list-inputs", action="store_true", help="List PDFs in dev/inputs and exit")
    args = parser.parse_args()

    if args.list_inputs:
        _list_inputs()
        return 0
    if not args.pdf:
        parser.error("--pdf is required (or pass --list-inputs)")

    pdf_path = _resolve_pdf(args.pdf)
    title = args.title or pdf_path.stem.replace("_", " ")
    cfg = PipelineConfig(
        pdf=pdf_path,
        title=title,
        author=args.author,
        course=args.course,
        run_root=args.run_root,
        build_dir=args.build_dir,
        prefer_remote_layout=args.prefer_remote_layout,
        aggregate=not args.no_aggregate,
        qa_enabled=not args.skip_qa,
        qa_attempt_compile=args.qa_compile,
    )
    state = run_pipeline(cfg, use_langchain=args.langchain)
    summary = {
        "run_dir": str(state.run_dir) if state.run_dir else None,
        "build_dir": str(cfg.build_dir.resolve()),
        "plan": str(state.plan_path) if state.plan_path else None,
        "consensus": str(state.consensus_path) if state.consensus_path else None,
        "snippets": str(state.snippets_dir) if state.snippets_dir else None,
        "qa_report": str(state.qa_report) if state.qa_report else None,
    }
    print(json.dumps(summary, indent=2))
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
