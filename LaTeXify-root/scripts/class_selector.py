#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Class Selector (RAG-driven)
- Reads run_dir/chunks.jsonl (+ chunks_meta.json if present)
- Scores content signals to pick LiX class and preamble options
- Writes:
    run_dir/class_decision.json
    run_dir/synthesis/main.tex  (compiling skeleton; KOMA fallback)

Hard constraints observed:
- Open-source only
- Determinism: seed=42 (logged)
- Strict LaTeX package policy; prefer listings over minted unless clearly code-heavy
"""
from __future__ import annotations
import argparse, json, re, os
from pathlib import Path
from typing import List, Dict, Any

SEED = 42

THEOREM_RE = re.compile(r"\b(Theorem|Lemma|Proposition|Definition|Corollary|Proof)\b", re.I)
HEADING_RE = re.compile(r"^\s*#{1,6}\s+\S", re.M)
CODEFENCE_RE = re.compile(r"^```", re.M)
MATH_RE = re.compile(r"(\$\$.*?\$\$|\$[^$]+\$)", re.S)
ASSIGNMENT_RE = re.compile(r"\b(Assignment|Report|Lab|Submission|Due|Student Name|Course|Instructor)\b", re.I)

def _load_chunks(p: Path) -> List[Dict[str, Any]]:
    rows = []
    with p.open("r", encoding="utf-8") as f:
        for line in f:
            line=line.strip()
            if not line: continue
            try: rows.append(json.loads(line))
            except: pass
    return rows

def _count_signals(rows: List[Dict[str, Any]]) -> Dict[str,int]:
    c = dict(theorems=0, headings=0, codefences=0, math=0, assignment=0)
    for r in rows:
        t = (r.get("text") or "").strip()
        if not t: continue
        c["theorems"]  += len(THEOREM_RE.findall(t))
        c["headings"]  += len(HEADING_RE.findall(t))
        c["codefences"]+= len(CODEFENCE_RE.findall(t))
        c["math"]      += len(MATH_RE.findall(t))
        c["assignment"]+= len(ASSIGNMENT_RE.findall(t))
    return c

def _infer_pages(rows: List[Dict[str,Any]]) -> int:
    mx = 0
    for r in rows:
        if isinstance(r.get("page_index"), int):
            mx = max(mx, int(r["page_index"]))
    if mx == 0:
        for r in rows:
            nm = r.get("page_name") or ""
            m = re.search(r"page-(\d+)", str(nm))
            if m:
                mx = max(mx, int(m.group(1)))
    return mx if mx>0 else 1

def decide(run_dir: Path) -> Dict[str,Any]:
    chunks_path = run_dir / "chunks.jsonl"
    if not chunks_path.exists():
        raise SystemExit(f"No chunks.jsonl found at {chunks_path}")
    chunks = _load_chunks(chunks_path)
    if not chunks:
        raise SystemExit("chunks.jsonl is empty.")

    pages = _infer_pages(chunks)
    sig = _count_signals(chunks)

    # Scoring
    score_textbook = 0
    score_article = 0

    # Length / hierarchy
    if pages >= 18: score_textbook += 3
    elif pages >= 10: score_textbook += 1
    else: score_article += 2

    if sig["headings"] >= 12: score_textbook += 2
    elif sig["headings"] >= 6: score_textbook += 1

    # Scholarly apparatus
    if sig["theorems"] >= 4: score_textbook += 2
    elif sig["theorems"] >= 1: score_textbook += 1

    # Assignment/report cues
    if sig["assignment"] >= 3: score_article += 2
    elif sig["assignment"] >= 1: score_article += 1

    # Math density nudges towards textbook
    if sig["math"] >= 10: score_textbook += 2
    elif sig["math"] >= 4: score_textbook += 1

    minted_recommended = sig["codefences"] >= 3  # advisory only

    chosen = "lix_textbook" if score_textbook >= score_article else "lix_article"

    preamble = {
        "class": chosen,
        "minted": minted_recommended,  # advisory only; skeleton uses listings
        "thmtools": sig["theorems"] >= 1,
        "mathpkg": True,
        "microtype": True,
        "hyperref": True,
    }

    return {
        "seed": SEED,
        "pages": pages,
        "signals": sig,
        "scores": {"lix_textbook": score_textbook, "lix_article": score_article},
        "decision": preamble,
        "notes": [
            "Skeleton uses KOMA (scrartcl) with listings to ensure first-try compile.",
            "If LiX classes are installed, switch \\documentclass to the chosen LiX class.",
            "If you want minted, ensure pygments + -shell-escape; otherwise keep listings."
        ]
    }

# Use a safe token __CHOSEN_CLASS__ so LaTeX braces aren't parsed by str.format()
SKELETON = r"""% Auto-generated skeleton (seed=42)
% Intended LiX class: __CHOSEN_CLASS__
\documentclass[11pt]{scrartcl} % Fallback for reliable compile. Switch to LiX when available.
\usepackage[margin=1in]{geometry}
\usepackage{microtype}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage[nameinlink,capitalise]{cleveref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{listings} % safer default than minted

\title{TITLE_PLACEHOLDER}
\author{AUTHOR_PLACEHOLDER}
\date{\today}

\begin{document}
\maketitle
\tableofcontents

\section*{About this document}
This PDF was generated by the LaTeXify pipeline. The class selector recommended \texttt{__CHOSEN_CLASS__} based on structure and content.
Switch to it by replacing the document class line with:
\begin{verbatim}
% \documentclass{__CHOSEN_CLASS__}
\end{verbatim}

\section{Introduction}
Write a short overview of the unit.

\section{Core Skills Covered}
Use bullets and cross-references.
\begin{itemize}
  \item Skill A
  \item Skill B
  \item Skill C
\end{itemize}

\section{Notes}
Add any assumptions or references here.

\end{document}
"""

def write_outputs(run_dir: Path, decision: Dict[str,Any]):
    # decision JSON
    (run_dir / "class_decision.json").write_text(
        json.dumps(decision, indent=2, ensure_ascii=False),
        encoding="utf-8"
    )
    # skeleton (under run_dir/synthesis)
    syn = run_dir / "synthesis"
    syn.mkdir(parents=True, exist_ok=True)
    # Safe token replace; avoids KeyError from str.format on LaTeX braces
    chosen = decision["decision"]["class"]
    tex = SKELETON.replace("__CHOSEN_CLASS__", chosen)
    (syn / "main.tex").write_text(tex, encoding="utf-8")

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--run_dir", required=True, help="Path to dev/runs/<STAMP>")
    args = ap.parse_args()
    run_dir = Path(args.run_dir)
    out = decide(run_dir)
    write_outputs(run_dir, out)
    print(json.dumps({
        "run_dir": str(run_dir),
        "decision_json": str(run_dir / "class_decision.json"),
        "skeleton": str(run_dir / "synthesis" / "main.tex"),
        "chosen_class": out["decision"]["class"],
        "minted_recommended": out["decision"]["minted"]
    }, indent=2))

if __name__ == "__main__":
    main()
